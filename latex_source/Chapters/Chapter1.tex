% Chapter Template

\chapter{Introduction} % Main chapter title

\label{Chapter1} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 1. \emph{Introduction}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title


In recent years, deep neural networks have achieved state of the art results in various tasks or domains, such as, computer vision, speech recognition and machine translation tasks~\citep{lecun2015deep}. These models have shown to be effective at learning abstract representations from the raw input (large training datasets), and the models have sufficient generalizability to be able to tackle different learning problems. These are desirable properties for the problem of relevance ranking in Information Retrieval (IR) and in recent years there have been a substantial number of works that applied these neural methods in IR displaying advances in state of the art.

Information retrieval is a core component in many real-world applications--Web search, digital libraries, e-commerce platforms and so on. The problem of relevance ranking in IR (\textit{ad-hoc} retrieval) is defined as--given a query and set of candidate documents, a scoring function determines the degree of relevance of the document to the query and finally produces a ranking list by sorting the relevance scores. Many different ranking models have been proposed including vector space models (TF-IDF), probabilistic retrieval models (BM25, QL) and learning to rank (LTR) approaches that applies machine learning to the ranking function achieving great improvements in retrieval effectiveness~\citep{liu2009learning}. However, successful LTR models relies heavily on hand-crafted feature engineering that is time-confusing, incomplete and over-specified. Thus, neural IR models that employ the use of shallow or deep neural networks for IR have been proposed as a solution to tackle the feature engineering problem of learning to rank, by using only automatically learned features from raw text input of the query and document. These neural IR models use vector representations of text, and have a large number of parameters that needs to be tuned with large-scale datasets in training~\citep{Mitra2017a}. Therefore, unlike traditional IR models, these models are more ``data-hungry'' and the performance increases as training data increases.

All existing neural IR can be broadly categorized based on whether they influence the query representation that encodes information need, or the document representation that captures distribution of information contained or estimate the mutual relevance based on patterns of matching between the query and document. They are categorized, as \textit{representation-based} approaches (DSSM~\citep{dssm13}, CDSSM~\citep{Shen2014a, Shen2014b}), and \textit{interaction-based} approaches (DRMM~\citep{Guo2016}, DUET~\citep{Mitra2017a}, MatchPyramid~\citep{matchpyramid16}, PACRR~\citep{pacrr17, co_pacrr_wsdm18}, K-NRM~\citep{KNRM17}). The representation-based approaches aimed to learn document representations to match with query representations, while interaction-based approaches learn from matching matrices between query and document. Recently, there have been works that focused on architectures that try to model the human relevance judgement process (DeepRank~\citep{Pang_deeprank_2017}) and on learning relevance signals at different granularities (i.e. passage-level or document-wide)~\citep{Fan_hint_2018}. The various neural ranking models learned from generating the features automatically have already outperformed several state-of-the-art LTR models with tens of hand crafted features~\citep{Pang_deeprank_2017, Fan_hint_2018}. There have been some interesting works whose focus has been on the training strategies of neural ranking models as not everyone has access to commercial large-scale training datasets~\citep{Dehghani_sigir17, dehghani2018fidelityweighted} and learning alternative indexing schemes for neural IR models~\citep{Zamani_neural_reranking_2018} that moves from the neural re-ranking strategies (\textit{telescoping}) adopted by most previous approaches.

With the spurt in performance of \textit{deep learning} in many domains, there has come a new wave of approaches trying to explain the decisions made by these complex machine learning models. Explainability and interpretability is at the heart of how one can  deploy NNs approaches in real-word applications and how humans will interact with them. These explanations can help debug models, determine training biases or understand decisions in simpler terms to build trust. With the recent progress of neural IR approaches that has shown state-of-the-art performance on certain benchmarks, the need to understand and analyze why these models are performing better or how they are connected to the classical IR approaches has become an important topic raised in the IR community~\citep{craswell2017sigir, Craswell2018sigir_forum}.

%------------------------------------------------------
%	SECTION 1
%------------------------------------------------------
\section{Motivation}
\textbf{Reproducibility} The rapid increase of new neural ranking models proposed in the literature, with each using different pre-processing strategies, different hyper-parameter choices, different benchmark datasets (public or large-scale private clickthrough data) and different scale of computational resources, highlights the issue of reproducibility and applicability of these new approaches. This has led to the focus of reproducibility of these methods that have been discussed in the IR community lately at relevant workshops~\citep{craswell2017sigir, Craswell2018sigir_forum} and also there has been the release of the large-scale dataset (MS-MARCO)~\citep{nguyen2016ms_marco} for the passage re-ranking task\footnote{\url{https://github.com/dfcf93/MSMARCO/blob/master/Ranking/README.md}} and TREC 2019 deep learning track\footnote{\url{https://trec.nist.gov/pubs/call2019.html}} for benchmarking emerging neural IR approaches.  

\textbf{Interpretability} The explainability of neural ranking models is largely unexplored. There have been few papers that focused on the interpretability of neural ranking models~\citep{Singh19} and on the diagnosis or analysis of different model components of the model empirically~\citep{PangLG0C17, Cohen18} or with the use of diagnostic datasets based on formal retrieval constraints~\citep{Rennings19}. It is interesting to see to what extent we can use the explainability approaches proposed in other domains (image or text classification) to understand the decisions of neural networks, which can be applied in the context of IR. Thus, its a challenging and promising direction of research in neural IR.

%------------------------------------------------------
%	SECTION 2
%------------------------------------------------------
\section{Contributions}

The work in this thesis can be divided into two parts--the first part focuses mainly on the reproducibility of various neural ranking models (both \textit{representation-based} and \textit{interaction-based}); and the second part focuses on the question--\textit{why} a particular document is relevant to a query for the various neural ranking models implemented part of the reproducibility experiments. 

We address the following questions in this thesis:
% \vspace{-1em}
\begin{itemize}
    \item What are the challenges in the reproducibility of the neural ranking models on the standard TREC Robust04 benchmark collection? Are we able to reproduce the same retrieval performance as mentioned in the papers? If not, why?\vspace{1em}
    \item How can we adapt the \textit{model-introspective} approach DeepSHAP to explain the output of neural ranking models?
    \item How different are the DeepSHAP explanations across the various implemented neural ranking models?
    \item How do the explanations from DeepSHAP compare with the explanations from the \textit{model-agnostic} approach LIME?
\end{itemize}

\section{Outline}
The rest of the thesis is organized as follows: In chapter~\ref{Chapter2}, we extensively cover all the related work of neural ranking models. In chapter~\ref{Chapter3}, we describe the fundamentals needed to understand the existing neural IR approaches and the interpretability approaches that we used in this thesis to understand the neural IR models. In chapter~\ref{Chapter4}, we discuss in detail the various neural ranking models along with the experimental setup and a discussion of the results for each model. In chapter~\ref{Chapter5}, we describe how existing interpretability approaches are adapted for the context of \textit{ad-hoc} retrieval and how they can be used to explain neural ranking models along with the  experimental evaluation of our approaches. Finally, in chapter~\ref{Chapter6} we conclude our work and propose directions for future research on the topic. 